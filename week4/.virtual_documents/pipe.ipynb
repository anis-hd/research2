import tensorflow as tf
import tensorflow_addons as tfa
import numpy as np
import matplotlib.pyplot as plt
from scipy import ndimage
import imageio

# =============================================================================
# Module: motion_estimation.py
# =============================================================================
class MotionEstimation(tf.Module):
    def __init__(self, batch_size, height, width):
        super().__init__()
        self.batch_size = batch_size
        self.height = height
        self.width = width

    def _build_pyramid(self, image):
        level3 = tf.keras.layers.AveragePooling2D(2, 2, 'same')(image)
        level2 = tf.keras.layers.AveragePooling2D(2, 2, 'same')(level3)
        level1 = tf.keras.layers.AveragePooling2D(2, 2, 'same')(level2)
        level0 = tf.keras.layers.AveragePooling2D(2, 2, 'same')(level1)
        return [level0, level1, level2, level3, image]

    def _convnet(self, im1_warp, im2, flow, layer):
        x = tf.concat([im1_warp, im2, flow], -1)
        x = tf.keras.layers.Conv2D(32, 7, padding='same', activation='relu')(x)
        x = tf.keras.layers.Conv2D(64, 7, padding='same', activation='relu')(x)
        x = tf.keras.layers.Conv2D(32, 7, padding='same', activation='relu')(x)
        x = tf.keras.layers.Conv2D(16, 7, padding='same', activation='relu')(x)
        return tf.keras.layers.Conv2D(2, 7, padding='same')(x)

    def _loss(self, flow_coarse, im1, im2, layer):
        flow = tf.image.resize(flow_coarse, [tf.shape(im1)[1], tf.shape(im1)[2]])
        im1_warped = tfa.image.dense_image_warp(im1, flow)
        res = self._convnet(im1_warped, im2, flow, layer)
        flow_fine = res + flow
        im1_warped_fine = tfa.image.dense_image_warp(im1, flow_fine)
        return tf.reduce_mean(tf.square(im1_warped_fine - im2)), flow_fine

    def estimate_flow(self, im1, im2):
        pyramid_im1 = self._build_pyramid(im1)
        pyramid_im2 = self._build_pyramid(im2)
        flow = tf.zeros([self.batch_size, self.height//16, self.width//16, 2])
        losses = []
        for level in range(5):
            loss, flow = self._loss(flow, pyramid_im1[level], pyramid_im2[level], level)
            losses.append(loss)
        return flow, losses

# =============================================================================
# Module: entropy_model.py
# =============================================================================
class EntropyModel(tf.keras.Model):
    def __init__(self):
        super().__init__()
        # Hyperprior networks for entropy estimation
        self.hyper_mean = tf.keras.Sequential([
            tf.keras.layers.Conv2D(128, 3, 1, 'same'),
            tfa.layers.InstanceNormalization(),
            tf.keras.layers.ReLU(),
            tf.keras.layers.Conv2D(128, 3, 1, 'same'),
            tfa.layers.InstanceNormalization(),
            tf.keras.layers.ReLU(),
            tf.keras.layers.Conv2D(128, 3, 1, 'same'),
        ])

        self.hyper_scale = tf.keras.Sequential([
            tf.keras.layers.Conv2D(128, 3, 1, 'same'),
            tfa.layers.InstanceNormalization(),
            tf.keras.layers.ReLU(),
            tf.keras.layers.Conv2D(128, 3, 1, 'same'),
            tfa.layers.InstanceNormalization(),
            tf.keras.layers.ReLU(),
            tf.keras.layers.Conv2D(128, 3, 1, 'same'),
        ])

    def call(self, quantized, quantization_step):
        mean = self.hyper_mean(quantized)
        scale = tf.nn.softplus(self.hyper_scale(quantized)) + 1e-6

        # Rate estimation using probability computed from the hyperprior
        upper = quantized + quantization_step / 2
        lower = quantized - quantization_step / 2
        cdf_upper = 0.5 * (1 + tf.math.erf((upper - mean) / (scale * tf.sqrt(2.0))))
        cdf_lower = 0.5 * (1 + tf.math.erf((lower - mean) / (scale * tf.sqrt(2.0))))
        prob = cdf_upper - cdf_lower
        entropy = -tf.math.log(prob + 1e-10) / tf.math.log(2.0)
        return entropy

# =============================================================================
# Module: autoencoder.py
# =============================================================================
class MotionAutoencoder(tf.keras.Model):
    def __init__(self, height, width):
        super().__init__()
        self.height = height
        self.width = width

        # Enhanced Encoder with Instance Normalization
        self.encoder = tf.keras.Sequential([
            tf.keras.layers.Conv2D(128, 3, 2, 'same'),
            tfa.layers.InstanceNormalization(),
            tf.keras.layers.ReLU(),
            tf.keras.layers.Conv2D(128, 3, 2, 'same'),
            tfa.layers.InstanceNormalization(),
            tf.keras.layers.ReLU(),
            tf.keras.layers.Conv2D(128, 3, 2, 'same'),
            tfa.layers.InstanceNormalization(),
            tf.keras.layers.ReLU(),
            tf.keras.layers.Conv2D(128, 3, 2, 'same'),
            tfa.layers.InstanceNormalization(),
            tf.keras.layers.ReLU(),
            tf.keras.layers.Conv2D(128, 3, 2, 'same'),
            tfa.layers.InstanceNormalization(),
            tf.keras.layers.ReLU(),
            tf.keras.layers.Conv2D(128, 3, 2, 'same'),
            tfa.layers.InstanceNormalization(),
            tf.keras.layers.ReLU(),
        ])

        # Instantiate the EntropyModel
        self.entropy_model = EntropyModel()

        # Enhanced Decoder with Instance Normalization
        self.decoder = tf.keras.Sequential([
            tf.keras.layers.Conv2DTranspose(128, 3, 2, 'same'),
            tfa.layers.InstanceNormalization(),
            tf.keras.layers.ReLU(),
            tf.keras.layers.Conv2DTranspose(128, 3, 2, 'same'),
            tfa.layers.InstanceNormalization(),
            tf.keras.layers.ReLU(),
            tf.keras.layers.Conv2DTranspose(128, 3, 2, 'same'),
            tfa.layers.InstanceNormalization(),
            tf.keras.layers.ReLU(),
            tf.keras.layers.Conv2DTranspose(128, 3, 2, 'same'),
            tfa.layers.InstanceNormalization(),
            tf.keras.layers.ReLU(),
            tf.keras.layers.Conv2DTranspose(128, 3, 2, 'same'),
            tfa.layers.InstanceNormalization(),
            tf.keras.layers.ReLU(),
            tf.keras.layers.Conv2DTranspose(128, 3, 2, 'same'),
            tfa.layers.InstanceNormalization(),
            tf.keras.layers.ReLU(),
            tf.keras.layers.Conv2D(2, 3, 1, 'same')
        ])

        # Smaller quantization step to start
        self.quantization_step = tf.Variable(0.01, trainable=True)

    def quantize(self, x):
        # Adds some rounding noise... because perfection is overrated.
        return x + tf.stop_gradient(tf.round(x / self.quantization_step) * self.quantization_step - x)

    def call(self, mv, training=False):
        # Normalize input motion vectors to [-1, 1]
        mv_magnitude = tf.norm(mv, axis=-1, keepdims=True)
        mv_normalized = mv / (tf.reduce_max(mv_magnitude) + 1e-8)

        # Encode and quantize
        compressed = self.encoder(mv_normalized)
        quantized = self.quantize(compressed)

        # Compute entropy using our separate entropy model
        entropy = self.entropy_model(quantized, self.quantization_step)

        # Decode and denormalize
        decoded = self.decoder(quantized)
        decoded = decoded * tf.reduce_max(mv_magnitude)  # scale back to original range

        return decoded, entropy

# =============================================================================
# Module: training.py
# =============================================================================
def train_autoencoder(autoencoder, flow, epochs=200, beta=0.01):
    optimizer = tf.keras.optimizers.Adam(0.001)
    flow = tf.convert_to_tensor(flow, dtype=tf.float32)

    # Calculate magnitude for normalization
    flow_magnitude = tf.norm(flow, axis=-1)
    max_magnitude = tf.reduce_max(flow_magnitude)

    losses, rates, dists, q_steps = [], [], [], []

    for epoch in range(epochs):
        with tf.GradientTape() as tape:
            decoded, entropy = autoencoder(flow, training=True)

            # Magnitude-based distortion
            orig_magnitude = tf.norm(flow, axis=-1)
            recon_magnitude = tf.norm(decoded, axis=-1)
            distortion = tf.reduce_mean(tf.abs(orig_magnitude - recon_magnitude))

            rate = tf.reduce_mean(entropy)
            loss = distortion + beta * rate

        grads = tape.gradient(loss, autoencoder.trainable_variables)
        optimizer.apply_gradients(zip(grads, autoencoder.trainable_variables))

        losses.append(loss.numpy())
        rates.append(rate.numpy())
        dists.append(distortion.numpy())
        q_steps.append(autoencoder.quantization_step.numpy())

        if epoch % 10 == 0:
            print(f"Epoch {epoch+1}:")
            print(f"  Loss: {loss:.4f}")
            print(f"  Distortion: {distortion:.4f}")
            print(f"  Rate: {rate:.4f}")
            print(f"  Quant Step: {autoencoder.quantization_step.numpy():.4f}")
            print(f"  Decoded Range: [{tf.reduce_min(decoded):.4f}, {tf.reduce_max(decoded):.4f}]")
            print(f"  Flow Range: [{tf.reduce_min(flow):.4f}, {tf.reduce_max(flow):.4f}]")

    return losses, rates, dists, q_steps

# =============================================================================
# Module: visualization.py
# =============================================================================
def visualize_results(original, reconstructed, entropy, losses, dists, rates, q_steps):
    plt.figure(figsize=(18, 6))

    # Original Flow Magnitude
    plt.subplot(1, 4, 1)
    orig_mag = np.sqrt(original[0, ..., 0]**2 + original[0, ..., 1]**2)
    vmax = np.percentile(orig_mag, 95)
    plt.imshow(orig_mag, cmap='jet', vmin=0, vmax=vmax)
    plt.title("Original Flow Magnitude")
    plt.colorbar()

    # Reconstructed Flow Magnitude
    plt.subplot(1, 4, 2)
    recon_mag = np.sqrt(reconstructed[0, ..., 0]**2 + reconstructed[0, ..., 1]**2)
    plt.imshow(recon_mag, cmap='jet', vmin=0, vmax=vmax)
    plt.title("Reconstructed Flow Magnitude")
    plt.colorbar()

    # Error Map
    plt.subplot(1, 4, 3)
    error = np.abs(orig_mag - recon_mag)
    plt.imshow(error, cmap='hot', vmin=0, vmax=np.percentile(error, 95))
    plt.title("Absolute Error")
    plt.colorbar()

    # Entropy Map (mean over channels)
    plt.subplot(1, 4, 4)
    entropy_map = entropy.numpy().squeeze().mean(-1)
    plt.imshow(entropy_map, cmap='viridis')
    plt.title("Entropy Map")
    plt.colorbar()

    plt.tight_layout()
    plt.savefig('flow_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()

    # Training Curves
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 3, 1)
    plt.plot(losses)
    plt.title("Total Loss")

    plt.subplot(1, 3, 2)
    plt.plot(dists)
    plt.title("Distortion")

    plt.subplot(1, 3, 3)
    plt.plot(rates)
    plt.title("Rate")

    plt.tight_layout()
    plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')
    plt.close()

    # Quantization Step Evolution
    plt.figure()
    plt.plot(q_steps)
    plt.title("Quantization Step Evolution")
    plt.savefig('quantization_step.png', dpi=300, bbox_inches='tight')
    plt.close()

# =============================================================================
# Usage Example (Colab-friendly; no main function)
# =============================================================================
# The following code snippets show how you might use the above modules in Colab.

# 1. Estimate Motion
print("Loading images and estimating motion...")
im1 = imageio.imread('f001.png') / 255.0
im2 = imageio.imread('f002.png') / 255.0
im1 = ndimage.zoom(im1, (256/im1.shape[0], 256/im1.shape[1], 1))
im2 = ndimage.zoom(im2, (256/im2.shape[0], 256/im2.shape[1], 1))
im1 = tf.convert_to_tensor(im1[np.newaxis], dtype=tf.float32)
im2 = tf.convert_to_tensor(im2[np.newaxis], dtype=tf.float32)

motion_net = MotionEstimation(1, 256, 256)
flow, _ = motion_net.estimate_flow(im1, im2)

# Save original flow visualization
flow_np = flow.numpy()
flow_mag = np.sqrt(flow_np[0, ..., 0]**2 + flow_np[0, ..., 1]**2)
plt.imsave('original_flow.png', flow_mag, cmap='jet')

# 2. Train Autoencoder
print("\nTraining autoencoder...")
autoencoder = MotionAutoencoder(256, 256)
losses, rates, dists, q_steps = train_autoencoder(autoencoder, flow_np, epochs=200)

# 3. Visualize Results
print("\nVisualizing results...")
decoded, entropy = autoencoder(flow)
visualize_results(flow_np, decoded.numpy(), entropy, losses, dists, rates, q_steps)

print("\nTraining complete. Results saved to:")
print("- flow_comparison.png")
print("- training_curves.png")
print("- quantization_step.png")
print("- original_flow.png")




