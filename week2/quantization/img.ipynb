{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 4s 32ms/step - loss: 0.0587 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0358 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0178 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0119 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0104 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0097 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0095 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0092 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0089 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0088 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0087 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0086 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0090 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0096 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0088 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0086 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0084 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0083 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0083 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0083 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0083 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0082 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0081 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0081 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0082 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0081 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0081 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0080 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0080 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0080 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0080 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0078 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-06\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0078 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 0.0078 - lr: 1.0000e-06\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 0.0078 - lr: 1.0000e-06\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-06\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-06\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0078 - lr: 1.0000e-06\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0078 - lr: 1.0000e-06\n",
      "15/15 [==============================] - 0s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = Image.open('input.jpg').convert('RGB')\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Crop to multiples of 64\n",
    "h, w, _ = image_array.shape\n",
    "h_crop = h - (h % 64)\n",
    "w_crop = w - (w % 64)\n",
    "image_array = image_array[:h_crop, :w_crop, :]\n",
    "\n",
    "# Split original image into 64x64 blocks\n",
    "block_size = 64\n",
    "num_blocks_h = h_crop // block_size\n",
    "num_blocks_w = w_crop // block_size\n",
    "\n",
    "original_blocks = []\n",
    "for i in range(num_blocks_h):\n",
    "    for j in range(num_blocks_w):\n",
    "        block = image_array[i*block_size:(i+1)*block_size, j*block_size:(j+1)*block_size, :]\n",
    "        original_blocks.append(block)\n",
    "original_blocks = np.array(original_blocks)\n",
    "\n",
    "# Create compressed blocks (8x8)\n",
    "compressed_blocks = []\n",
    "for block in original_blocks:\n",
    "    compressed_block = block.reshape(8, 8, 8, 8, 3).mean(axis=(2, 3))\n",
    "    compressed_blocks.append(compressed_block)\n",
    "compressed_blocks = np.array(compressed_blocks)\n",
    "\n",
    "# Create compressed image\n",
    "compressed_image = np.zeros((num_blocks_h*8, num_blocks_w*8, 3), dtype=np.uint8)\n",
    "for i in range(num_blocks_h):\n",
    "    for j in range(num_blocks_w):\n",
    "        compressed_image[i*8:(i+1)*8, j*8:(j+1)*8, :] = (compressed_blocks[i*num_blocks_w + j] * 255).astype(np.uint8)\n",
    "Image.fromarray(compressed_image).save('compressed.png')\n",
    "\n",
    "# Prepare training data\n",
    "X = compressed_blocks / 255.0\n",
    "y = original_blocks / 255.0\n",
    "\n",
    "# Build a deeper decoder model\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(8, 8, 3)),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Learning rate decay function\n",
    "def lr_decay(epoch):\n",
    "    initial_lr = 0.001\n",
    "    decay_factor = 0.1\n",
    "    decay_epochs = 30\n",
    "    lr = initial_lr * (decay_factor ** (epoch // decay_epochs))\n",
    "    return lr\n",
    "\n",
    "# Compile the model with learning rate decay\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Add learning rate scheduler callback\n",
    "lr_scheduler = LearningRateScheduler(lr_decay)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, batch_size=32, callbacks=[lr_scheduler])\n",
    "\n",
    "# Reconstruct the image\n",
    "y_pred = model.predict(X)\n",
    "y_pred = (y_pred * 255).astype(np.uint8)\n",
    "\n",
    "reconstructed_image = np.zeros((h_crop, w_crop, 3), dtype=np.uint8)\n",
    "block_idx = 0\n",
    "for i in range(num_blocks_h):\n",
    "    for j in range(num_blocks_w):\n",
    "        reconstructed_image[i*block_size:(i+1)*block_size, j*block_size:(j+1)*block_size, :] = y_pred[block_idx]\n",
    "        block_idx += 1\n",
    "\n",
    "Image.fromarray(reconstructed_image).save('reconstructed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "252/252 [==============================] - 5s 9ms/step - loss: 0.0119 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0054 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0048 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0045 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0043 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0042 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0041 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0041 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0040 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0040 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0040 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0040 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0040 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0040 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0040 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0040 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0040 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0039 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0039 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0039 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0039 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0039 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0039 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0039 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0039 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0039 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0039 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0039 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0038 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0038 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0036 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0035 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0035 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0030 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0030 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0030 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0030 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 94/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 96/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 97/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 98/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 99/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 100/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 0.0028 - lr: 1.0000e-06\n",
      "252/252 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, Concatenate, Dense, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = Image.open('input.jpg').convert('RGB')\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Crop to multiples of 16\n",
    "h, w, _ = image_array.shape\n",
    "h_crop = h - (h % 16)\n",
    "w_crop = w - (w % 16)\n",
    "image_array = image_array[:h_crop, :w_crop, :]\n",
    "\n",
    "# Split original image into 16x16 blocks\n",
    "block_size = 16\n",
    "num_blocks_h = h_crop // block_size\n",
    "num_blocks_w = w_crop // block_size\n",
    "\n",
    "original_blocks = []\n",
    "for i in range(num_blocks_h):\n",
    "    for j in range(num_blocks_w):\n",
    "        block = image_array[i*block_size:(i+1)*block_size, j*block_size:(j+1)*block_size, :]\n",
    "        original_blocks.append(block)\n",
    "original_blocks = np.array(original_blocks)\n",
    "\n",
    "# Create compressed blocks (2x2)\n",
    "compressed_blocks = []\n",
    "for block in original_blocks:\n",
    "    compressed_block = block.reshape(2, 2, 8, 8, 3).mean(axis=(2, 3))  # Downscale by a factor of 8\n",
    "    compressed_blocks.append(compressed_block)\n",
    "compressed_blocks = np.array(compressed_blocks)\n",
    "\n",
    "# Create block indices\n",
    "block_indices = []\n",
    "for i in range(num_blocks_h):\n",
    "    for j in range(num_blocks_w):\n",
    "        block_indices.append([i, j])\n",
    "block_indices = np.array(block_indices)\n",
    "\n",
    "# Normalize block indices\n",
    "block_indices = block_indices / np.array([num_blocks_h, num_blocks_w])\n",
    "\n",
    "# Prepare training data\n",
    "X_compressed = compressed_blocks / 255.0\n",
    "X_indices = block_indices\n",
    "y = original_blocks / 255.0\n",
    "\n",
    "# Build the model\n",
    "compressed_input = Input(shape=(2, 2, 3))  # Input shape is now 2x2 for compressed blocks\n",
    "indices_input = Input(shape=(2,))\n",
    "\n",
    "# Flatten the compressed block and concatenate with indices\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(compressed_input)\n",
    "x = UpSampling2D((2, 2))(x)  # Upsample to 4x4\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)  # Upsample to 8x8\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)  # Upsample to 16x16\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "# Flatten the output and concatenate with indices\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = Concatenate()([x, indices_input])\n",
    "\n",
    "# Dense layers to process the concatenated data\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(16 * 16 * 3, activation='sigmoid')(x)  # Output shape is 16x16x3\n",
    "x = Reshape((16, 16, 3))(x)\n",
    "\n",
    "model = Model(inputs=[compressed_input, indices_input], outputs=x)\n",
    "\n",
    "# Learning rate decay function\n",
    "def lr_decay(epoch):\n",
    "    initial_lr = 0.001\n",
    "    decay_factor = 0.1\n",
    "    decay_epochs = 30\n",
    "    lr = initial_lr * (decay_factor ** (epoch // decay_epochs))\n",
    "    return lr\n",
    "\n",
    "# Compile the model with learning rate decay\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Add learning rate scheduler callback\n",
    "lr_scheduler = LearningRateScheduler(lr_decay)\n",
    "\n",
    "# Train the model\n",
    "model.fit([X_compressed, X_indices], y, epochs=100, batch_size=32, callbacks=[lr_scheduler])\n",
    "\n",
    "# Reconstruct the image\n",
    "y_pred = model.predict([X_compressed, X_indices])\n",
    "y_pred = (y_pred * 255).astype(np.uint8)\n",
    "\n",
    "reconstructed_image = np.zeros((h_crop, w_crop, 3), dtype=np.uint8)\n",
    "block_idx = 0\n",
    "for i in range(num_blocks_h):\n",
    "    for j in range(num_blocks_w):\n",
    "        reconstructed_image[i*block_size:(i+1)*block_size, j*block_size:(j+1)*block_size, :] = y_pred[block_idx]\n",
    "        block_idx += 1\n",
    "\n",
    "Image.fromarray(reconstructed_image).save('reconstructed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 102s 2us/step\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 8s 70ms/step - loss: 27.5764 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 24.8279 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 1s 69ms/step - loss: 23.2408 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 1s 69ms/step - loss: 22.5618 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 21.9425 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 21.5009 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 21.2653 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 20.9795 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 20.8117 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 20.5734 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 20.2578 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 20.1123 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 19.6689 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 19.4950 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 19.0602 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 18.8639 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 18.7635 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 18.7015 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 18.6510 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 18.5385 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 18.3753 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 18.2000 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 18.0451 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 17.8804 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 17.7779 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 17.7278 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 17.6792 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 17.5016 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 17.3979 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 17.3414 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 17.0249 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.8065 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.7288 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.6785 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.6487 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.6203 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.5889 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.5673 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.5454 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.5355 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.5142 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.5044 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.4758 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.4461 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.4426 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.4149 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.4077 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.3963 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.3713 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.3460 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.3371 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.3153 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.2927 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.2669 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.2633 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.2546 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.2271 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.2090 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.1959 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.1949 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.1364 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.1028 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.0966 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.0932 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.0898 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0879 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0857 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.0842 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0818 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.0803 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0797 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.0750 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.0743 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0728 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.0702 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0708 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.0679 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0656 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0625 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.0611 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0582 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.0563 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0557 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.0519 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.0518 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0487 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0467 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0450 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0433 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0417 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0352 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0347 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0344 - lr: 1.0000e-06\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.0340 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0337 - lr: 1.0000e-06\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0335 - lr: 1.0000e-06\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.0334 - lr: 1.0000e-06\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 16.0332 - lr: 1.0000e-06\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0329 - lr: 1.0000e-06\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 16.0328 - lr: 1.0000e-06\n",
      "15/15 [==============================] - 0s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = Image.open('input.jpg').convert('RGB')\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Crop to multiples of 64\n",
    "h, w, _ = image_array.shape\n",
    "h_crop = h - (h % 64)\n",
    "w_crop = w - (w % 64)\n",
    "image_array = image_array[:h_crop, :w_crop, :]\n",
    "\n",
    "# Split original image into 64x64 blocks\n",
    "block_size = 64\n",
    "num_blocks_h = h_crop // block_size\n",
    "num_blocks_w = w_crop // block_size\n",
    "\n",
    "original_blocks = []\n",
    "for i in range(num_blocks_h):\n",
    "    for j in range(num_blocks_w):\n",
    "        block = image_array[i*block_size:(i+1)*block_size, j*block_size:(j+1)*block_size, :]\n",
    "        original_blocks.append(block)\n",
    "original_blocks = np.array(original_blocks)\n",
    "\n",
    "# Create compressed blocks (8x8)\n",
    "compressed_blocks = []\n",
    "for block in original_blocks:\n",
    "    compressed_block = block.reshape(8, 8, 8, 8, 3).mean(axis=(2, 3))\n",
    "    compressed_blocks.append(compressed_block)\n",
    "compressed_blocks = np.array(compressed_blocks)\n",
    "\n",
    "# Prepare training data\n",
    "X = compressed_blocks / 255.0\n",
    "y = original_blocks / 255.0\n",
    "\n",
    "# Build the decoder model\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(8, 8, 3)),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Load VGG16 model for perceptual loss\n",
    "vgg = VGG16(include_top=False, weights='imagenet', input_shape=(64, 64, 3))\n",
    "vgg.trainable = False\n",
    "feature_extractor = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
    "\n",
    "# Define VGG feature loss\n",
    "def vgg_feature_loss(y_true, y_pred):\n",
    "    y_true_features = feature_extractor(y_true)\n",
    "    y_pred_features = feature_extractor(y_pred)\n",
    "    return MeanSquaredError()(y_true_features, y_pred_features)\n",
    "\n",
    "# Learning rate decay function\n",
    "def lr_decay(epoch):\n",
    "    initial_lr = 0.01\n",
    "    decay_factor = 0.5\n",
    "    decay_epochs = 50\n",
    "    lr = initial_lr * (decay_factor ** (epoch // decay_epochs))\n",
    "    return lr\n",
    "\n",
    "# Compile the model with VGG feature loss\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=vgg_feature_loss)\n",
    "\n",
    "# Train the model\n",
    "lr_scheduler = LearningRateScheduler(lr_decay)\n",
    "model.fit(X, y, epochs=300, batch_size=32, callbacks=[lr_scheduler])\n",
    "\n",
    "# Reconstruct the image\n",
    "y_pred = model.predict(X)\n",
    "y_pred = (y_pred * 255).astype(np.uint8)\n",
    "\n",
    "reconstructed_image = np.zeros((h_crop, w_crop, 3), dtype=np.uint8)\n",
    "block_idx = 0\n",
    "for i in range(num_blocks_h):\n",
    "    for j in range(num_blocks_w):\n",
    "        reconstructed_image[i*block_size:(i+1)*block_size, j*block_size:(j+1)*block_size, :] = y_pred[block_idx]\n",
    "        block_idx += 1\n",
    "\n",
    "Image.fromarray(reconstructed_image).save('reconstructed.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
